{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.246347453321581e-06\n",
      "6.951395840284729e-06\n"
     ]
    }
   ],
   "source": [
    "%run feature_extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_categories(x):\n",
    "    if x == 'info_news':\n",
    "        return 0\n",
    "    elif x == 'celebrity':\n",
    "        return 1\n",
    "    elif x == 'plan':\n",
    "        return 2\n",
    "    elif x == 'requests':\n",
    "        return 3\n",
    "    elif x == 'rumors':\n",
    "        return 4\n",
    "    elif x == 'advice':\n",
    "        return 5\n",
    "    elif x == 'restrictions':\n",
    "        return 6\n",
    "    elif x == 'personal':\n",
    "        return 7\n",
    "    elif x == 'unrelated':\n",
    "        return 8\n",
    "    elif x == 'others':\n",
    "        return 9\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1=pd.read_pickle('output/train_3_original.pkl')\n",
    "dev_1=pd.read_pickle('output/dev_1_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, stance_train, category_train = train_1.loc[:,\"tokens\"],train_1.loc[:,\"stance\"],train_1.loc[:,\"category\"]\n",
    "sentences_dev, stance_dev, category_dev = dev_1.loc[:,\"tokens\"],dev_1.loc[:,\"stance\"],dev_1.loc[:,\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CBOW & Skip Gram Features for training and dev\n",
    "X_train_cbow_w2v, X_train_sg_w2v = get_word_embeddings_features(sentences_train)\n",
    "X_dev_cbow_w2v, X_dev_sg_w2v = get_word_embeddings_features(sentences_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train_cbow_w2v + X_train_sg_w2v\n",
    "x_dev = X_dev_cbow_w2v + X_dev_sg_w2v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Fitting The Stance Detection Model using Logistic Regression (W2v)\n",
    "lr_w2v=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v.fit(x_train, stance_train)  #model\n",
    "\n",
    "#Predict y value for test dataset\n",
    "stance_predict = lr_w2v.predict(x_dev)\n",
    "stance_prob = lr_w2v.predict_proba(x_dev)[:,1]\n",
    "\n",
    "#Fitting The Classification Model using Logistic Regression (W2v)\n",
    "lr_w2v2=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v2.fit(x_train, category_train)  #model\n",
    "\n",
    "#Predict y value for test dataset\n",
    "categ_predict = lr_w2v2.predict(x_dev)\n",
    "categ_prob = lr_w2v2.predict_proba(x_dev)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.80      0.89      1000\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.33      0.27      0.30      1000\n",
      "weighted avg       1.00      0.80      0.89      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(stance_predict,stance_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      advice       0.00      0.00      0.00         0\n",
      "   celebrity       0.00      0.00      0.00         1\n",
      "   info_news       0.00      0.00      0.00         0\n",
      "      others       0.00      0.00      0.00         0\n",
      "    personal       0.00      0.00      0.00         0\n",
      "        plan       0.00      0.00      0.00         0\n",
      "    requests       0.90      0.02      0.04       963\n",
      "restrictions       0.00      0.00      0.00         0\n",
      "      rumors       0.00      0.00      0.00         0\n",
      "   unrelated       0.19      0.19      0.19        36\n",
      "\n",
      "    accuracy                           0.03      1000\n",
      "   macro avg       0.11      0.02      0.02      1000\n",
      "weighted avg       0.87      0.03      0.04      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(categ_predict,category_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8091afc18dd617945c9068b3bbeac349744316d3496a8fb9601c7f2d857f79fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
