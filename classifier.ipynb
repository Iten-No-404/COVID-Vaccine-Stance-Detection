{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 0.5714285714285714, 0.2857142857142857, 0.5, 0.007874015748031496, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.047619047619047616, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 0.25, 1.0, 0.125, 0.03003003003003003, 0.06666666666666667, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Cosine similarity between 'لقاح' and 'كورونا' - CBOW :  0.99884444\n",
      "Cosine similarity between 'لقاح' and 'صيفي' - CBOW :  0.780025\n",
      "Cosine similarity between 'لقاح' and 'كورونا' - Skip Gram :  0.86223567\n",
      "Cosine similarity between 'لقاح' and 'صيفي' - Skip Gram :  0.6852195\n"
     ]
    }
   ],
   "source": [
    "%run feature_extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1=pd.read_pickle('output/train_1_arabert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_1=pd.read_pickle('output/dev_1_arabert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>stance</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>2</td>\n",
       "      <td>[بيل, غيتس, يتلقى, لقاح, كوفيد, من, غير, تصوير...</td>\n",
       "      <td>[[tensor(-0.0219), tensor(-0.2168), tensor(0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
       "      <td>info_news</td>\n",
       "      <td>2</td>\n",
       "      <td>[وزير, صح, لحد, يوم, تحديد, هل, ##أ, بم, ##ؤتم...</td>\n",
       "      <td>[[tensor(0.0091), tensor(-0.2327), tensor(0.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
       "      <td>info_news</td>\n",
       "      <td>2</td>\n",
       "      <td>[قول, رح, يكون, ##و, اد, مسؤولي, ب, لبنان, ما,...</td>\n",
       "      <td>[[tensor(-0.0363), tensor(-0.2631), tensor(0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>2</td>\n",
       "      <td>[تركيا, وزير, صح, فخر, دين, قو, ##جة, يتلقى, أ...</td>\n",
       "      <td>[[tensor(-0.4569), tensor(-0.3163), tensor(0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
       "      <td>personal</td>\n",
       "      <td>1</td>\n",
       "      <td>[وئام, وهاب, يشتم, دول, خليجي, في, كل, طل, إعل...</td>\n",
       "      <td>[[tensor(-0.4959), tensor(-0.6038), tensor(0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...</td>\n",
       "      <td>info_news</td>\n",
       "      <td>1</td>\n",
       "      <td>[لقاح, كورونا, في, أميركا, قلق, متزايد, من, تو...</td>\n",
       "      <td>[[tensor(-0.3532), tensor(-0.1044), tensor(0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...</td>\n",
       "      <td>info_news</td>\n",
       "      <td>2</td>\n",
       "      <td>[لبنان, اشترى, مليون, لقاح, امريكي, اذ, شل, يل...</td>\n",
       "      <td>[[tensor(-0.0328), tensor(-0.2250), tensor(0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>من عوارض لقاح كورونا&lt;LF&gt;هو تهكير حسابك عتويتر&lt;...</td>\n",
       "      <td>personal</td>\n",
       "      <td>1</td>\n",
       "      <td>[من, عوارض, لقاح, كورونا, هو, ته, ##كير, حساب,...</td>\n",
       "      <td>[[tensor(-0.1049), tensor(-0.2332), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>1</td>\n",
       "      <td>[هناك, مليونير, في, لبنان, ماذا, لو, فرض, ضريب...</td>\n",
       "      <td>[[tensor(-0.0399), tensor(-0.4231), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...</td>\n",
       "      <td>info_news</td>\n",
       "      <td>2</td>\n",
       "      <td>[دعبول, حضر, منو, أنت, تطلب, من, قائد, دول, إس...</td>\n",
       "      <td>[[tensor(0.0334), tensor(-0.1388), tensor(0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   category  stance  \\\n",
       "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...  celebrity       2   \n",
       "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...  info_news       2   \n",
       "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...  info_news       2   \n",
       "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...  celebrity       2   \n",
       "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...   personal       1   \n",
       "5  لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...  info_news       1   \n",
       "6  لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...  info_news       2   \n",
       "7  من عوارض لقاح كورونا<LF>هو تهكير حسابك عتويتر<...   personal       1   \n",
       "8  هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...  unrelated       1   \n",
       "9  دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...  info_news       2   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [بيل, غيتس, يتلقى, لقاح, كوفيد, من, غير, تصوير...   \n",
       "1  [وزير, صح, لحد, يوم, تحديد, هل, ##أ, بم, ##ؤتم...   \n",
       "2  [قول, رح, يكون, ##و, اد, مسؤولي, ب, لبنان, ما,...   \n",
       "3  [تركيا, وزير, صح, فخر, دين, قو, ##جة, يتلقى, أ...   \n",
       "4  [وئام, وهاب, يشتم, دول, خليجي, في, كل, طل, إعل...   \n",
       "5  [لقاح, كورونا, في, أميركا, قلق, متزايد, من, تو...   \n",
       "6  [لبنان, اشترى, مليون, لقاح, امريكي, اذ, شل, يل...   \n",
       "7  [من, عوارض, لقاح, كورونا, هو, ته, ##كير, حساب,...   \n",
       "8  [هناك, مليونير, في, لبنان, ماذا, لو, فرض, ضريب...   \n",
       "9  [دعبول, حضر, منو, أنت, تطلب, من, قائد, دول, إس...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[tensor(-0.0219), tensor(-0.2168), tensor(0.3...  \n",
       "1  [[tensor(0.0091), tensor(-0.2327), tensor(0.43...  \n",
       "2  [[tensor(-0.0363), tensor(-0.2631), tensor(0.1...  \n",
       "3  [[tensor(-0.4569), tensor(-0.3163), tensor(0.5...  \n",
       "4  [[tensor(-0.4959), tensor(-0.6038), tensor(0.2...  \n",
       "5  [[tensor(-0.3532), tensor(-0.1044), tensor(0.3...  \n",
       "6  [[tensor(-0.0328), tensor(-0.2250), tensor(0.2...  \n",
       "7  [[tensor(-0.1049), tensor(-0.2332), tensor(-0....  \n",
       "8  [[tensor(-0.0399), tensor(-0.4231), tensor(-0....  \n",
       "9  [[tensor(0.0334), tensor(-0.1388), tensor(0.01...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [بيل, غيتس, يتلقى, لقاح, كوفيد, من, غير, تصوير...\n",
       "1       [وزير, صح, لحد, يوم, تحديد, هل, ##أ, بم, ##ؤتم...\n",
       "2       [قول, رح, يكون, ##و, اد, مسؤولي, ب, لبنان, ما,...\n",
       "3       [تركيا, وزير, صح, فخر, دين, قو, ##جة, يتلقى, أ...\n",
       "4       [وئام, وهاب, يشتم, دول, خليجي, في, كل, طل, إعل...\n",
       "                              ...                        \n",
       "6983    [اتحاد, دولي, مكافح, عدوي, يجب, تطعيم, من, سكا...\n",
       "6984    [وباء, أخطر, على, كر, أرضي, ليس, كورونا, بل, أ...\n",
       "6985                  [جرع, اولى, من, لقاح, كورونا, رابط]\n",
       "6986    [بعد, حظر, خامنئي, لقاح, غربي, طهران, صدد, إجا...\n",
       "6987    [مع, تصاعد, قلق, إثر, حال, وفا, بين, متلقي, لق...\n",
       "Name: tokenized, Length: 6988, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.loc[:,\"tokenized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       celebrity\n",
       "1       info_news\n",
       "2       info_news\n",
       "3       celebrity\n",
       "4        personal\n",
       "          ...    \n",
       "6983    info_news\n",
       "6984       others\n",
       "6985    info_news\n",
       "6986    info_news\n",
       "6987    info_news\n",
       "Name: category, Length: 6988, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.loc[:,\"tokenized\"]\n",
    "# lables\n",
    "train_1.loc[:,\"stance\"]\n",
    "train_1.loc[:,\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_categories(x):\n",
    "    if x == 'info_news':\n",
    "        return 0\n",
    "    elif x == 'celebrity':\n",
    "        return 1\n",
    "    elif x == 'plan':\n",
    "        return 2\n",
    "    elif x == 'requests':\n",
    "        return 3\n",
    "    elif x == 'rumors':\n",
    "        return 4\n",
    "    elif x == 'advice':\n",
    "        return 5\n",
    "    elif x == 'restrictions':\n",
    "        return 6\n",
    "    elif x == 'personal':\n",
    "        return 7\n",
    "    elif x == 'unrelated':\n",
    "        return 8\n",
    "    elif x == 'others':\n",
    "        return 9\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_padding(data_train, data_dev):\n",
    "    max_len = 0\n",
    "    for i in range(len(data_train)):      \n",
    "        max_len =max(max_len,len (data_train[i]))\n",
    "    for i in range(len(data_dev)):\n",
    "        max_len =max(max_len,len (data_dev[i]))     \n",
    "    return  max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=get_max_padding(train_1.loc[:,\"tokenized\"], dev_1.loc[:,\"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sentences,stance,category,max_len):   \n",
    "    pad_words = [\"باد\"]\n",
    "    for i in range(len(sentences)):\n",
    "        if len(sentences[i] )< max_len:\n",
    "            pad = [\"باد\"]*(max_len- len(sentences[i]))\n",
    "            sentences[i] = sentences[i]+ pad\n",
    "    category =category.apply(edit_categories)\n",
    "    return sentences,category,stance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,category_train,stance_train = process_data(train_1.loc[:,\"tokenized\"],train_1.loc[:,\"stance\"],train_1.loc[:,\"category\"],max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rorod\\miniforge3\\envs\\new_python_nlp_2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sentences_dev,category_dev,stance_dev = process_data(dev_1.loc[:,\"tokenized\"],dev_1.loc[:,\"stance\"],dev_1.loc[:,\"category\"],max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصحفي كان ما عندي مشكلة معوا.<LF>بس انوا بفايزر هو اللقاح الوحيد الآمن بالعالم لأ حبيبي هاي فيها نفاق واضح.<LF>عفوا يعني.<LF>مش إنوا مجبورين فيه وما قادر تجبر الدولة المارقة تدفع مصاري تجيب لقاح تاني.<LF>يلا باي'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_1.loc[:,\"tokenized\"][1]\n",
    "train_1.loc[:,\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6988 6988 6988\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_train),len(category_train),len(stance_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_dev),len(category_dev),len(stance_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بيل غيتس يتلقى لقاح تصوير الابرة السيرنجة الدواء لابس بولو صيفي عز الشتاء يقول ان احدى مزايا عمر ال عاما انه مؤهل للحصول اللقاح يعنى يحتاج اللقاح عمره اصغر\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train=sentences_train\n",
    "sentences_dev= sentences_dev\n",
    "new_sentences_train=[]\n",
    "new_sentences_dev=[]\n",
    "for sentence in sentences_train:\n",
    "    new_sentences_train.append(' '.join(sentence))\n",
    "for sentence in sentences_dev:\n",
    "    new_sentences_dev.append(' '.join(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_tf_idf_train,tfidf=get_TF_IDF(new_sentences_train)\n",
    "\n",
    "# tf_idf_train=assign_tf_idf(sentences_train,dict_tf_idf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train=convert_ngrams_probablities(3,new_sentences_train)\n",
    "prob_dev=convert_ngrams_probablities(3, new_sentences_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(prob_dev[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6988"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boost 100 weak decision trees\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "#GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "\n",
    "model = model.fit(prob_train, stance_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Accuracy is {78.3}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(prob_dev)\n",
    "acc = {metrics.accuracy_score(stance_dev, predictions) * 100}\n",
    "print(f\" Model Accuracy is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boost 100 weak decision trees\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "#GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "\n",
    "model = model.fit(prob_train, category_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Accuracy is {56.699999999999996}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(prob_dev)\n",
    "acc = {metrics.accuracy_score(category_dev, predictions) * 100}\n",
    "print(f\" Model Accuracy is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6988"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(prob_train)\n",
    "len(stance_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=[]\n",
    "for i in range(0, len(stance_train)):\n",
    "    x_data .append([stance_train[i],prob_train[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=[]\n",
    "for i in range(0, len(stance_dev)):\n",
    "    y_data .append([stance_dev[i],prob_dev[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm,metrics\n",
    "\n",
    "\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "classifier_linear.fit(prob_train, category_train)\n",
    "\n",
    "predictions  = classifier_linear.predict(prob_dev)\n",
    "print(metrics.accuracy_score(stance_dev, predictions) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.000000000000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "classifier_linear.fit(prob_train, category_train)\n",
    "#???????????????????????????????????????????????????? so bad? with this feature\n",
    "predictions  = classifier_linear.predict(prob_dev)\n",
    "print(metrics.accuracy_score(stance_dev, predictions) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model(naive bayes) and training. \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(prob_train, stance_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.4\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(prob_dev)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(stance_dev, predicted)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.47475454,  0.40165523,  1.68081787,  2.88940715,  0.91704519,\n",
       "       -3.07950644,  4.39961206,  0.72464273, -4.86563631, -6.06338084,\n",
       "       -1.22209949, -0.4699618 ,  1.01222748, -0.6899355 , -0.53000581,\n",
       "        6.86966784, -3.27211075, -6.59044146, -2.21290585, -3.139579  ])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model(naive bayes) and training. \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(prob_train, category_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.200000000000001\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(prob_dev)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(category_dev, predicted)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error in cross vald\n",
    "# error in TF-IDF beccause bug in text \n",
    "# category low values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcf9cbd0c10e7b20be0354504d5dd91617ed7515deed89fb2407bea1e8233e1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
